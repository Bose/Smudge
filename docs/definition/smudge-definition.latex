\documentclass{article}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{semantic}
\usepackage{syntax}
\usepackage{verbatimbox}

\newcommand{\dom}{\operatorname{dom}}
\newcommand{\instantiates}{\operatorname{<:}}
\newcommand{\issatisfied}{\operatorname{is\, satisfied}}
\newcommand{\isfresh}{\operatorname{is\, fresh}}

\newcommand{\void}{\texttt{void}}

\newcommand{\proves}[2]{#1 \vdash #2}
\newcommand{\hastype}[3]{\proves{#1}{#2 : #3}}
\newcommand{\tuple}[1]{\left\langle #1 \right\rangle}
\newcommand{\yield}[2]{\tuple{#1} \rightarrow \tuple{#2}}

\title{The Smudge Language Definition}

\begin{document}

\maketitle

\section*{Grammar of Smudge}
Smudge's syntax is comprised of top-level modules composed of one or more state
machines, in turn composed of one or more comma-separated transient- or
non-transient states.  Non-transient states are made up of zero or more enter
and exit side effects and one or more comma-separated event handlers.  Event
handlers are either ``arrow'' (transitioning) or ``dash'' (non-transitioning)
declarations, whose side effects can either be host functions or Smudge events.
All identifiers can contain any character (when quoted) except host functions,
which are conservatively limited to C-style identifiers.

The rules are as follows:

\setlength{\grammarindent}{6em}
\begin{grammar}
\input{syntax.latex}
\end{grammar}

\section*{Type inference in Smudge}
The types of events and side effects in Smudge can be both explicit and
implicit, as functions can be supplied both with and without type hints.
Accordingly, types within a single module are inferred using a deterministic
constraint solver.  Constraints are satisfied through monomorphic or subtype
polymorphic unification, depending on the flags supplied at invocation.

To construct these rules, both the notation of natural deduction for type
inference and the notation for automata are useful here, with a slight
modification: rather than a machine being represented by a top-level structure
composed of states, symbols, and uniform total transitions, the symbols
(referred to as events) are nested behind the states, and nested within events
are transitions composed of a sequence of side-effectful computation
statements, whose types can be non-uniform.  For clarity, the following
conventions are used:
\begin{itemize}
    \item $\Gamma$ refers to the environment of types
    \item $\tau$ refers to either a type or a type variable
    \item $\alpha$ refers to a type variable
    \item $C$ refers to the set of constraints
    \item $\theta$ refers to the substitutions
    \item $x$ refers to an identifier

    \item $m$ refers to a single state machine
    \item $q$ refers to a single state
    \item $a$ refers to a single input event
    \item $\delta$ refers to a total transition function for a state and event
    \item $\check{\delta}$ refers to a named side-effectful partial transition
\end{itemize}

The definition phase initiates elaboration, which is followed by constraint
inference, then by unification, and finally by instantiation.

\subsection*{Definition rules}
During definition, each module is inspected, and names are collected and
assigned type variables in the type environment $\Gamma$.

All names are fully-qualified.
\[
    \inference[ModuleDef]
    {\yield{m_1,\Gamma}{\Gamma_1}&\ldots&\yield{m_n,\Gamma_{n-1}}{\Gamma_n}\\
     \proves{C,\Gamma_n}{m_1,\ldots,m_n}\\
     \theta C\issatisfied&\theta\Gamma=\Gamma}
    {\yield{\textsc{module}(\tuple{m_1,\ldots,m_n}),\Gamma}{\theta\Gamma_n}}
\]

\[
    \inference[StateMachineDef]
    {\yield{q_1,\Gamma}{\Gamma_1}&\ldots&\yield{q_n,\Gamma_{n-1}}{\Gamma_n}}
    {\yield{\textsc{statemachine}(m,\tuple{q_1,\ldots,q_n}),\Gamma}{\Gamma_n}}
\]

\[
    \inference[StateDef]
    {\yield{a_1,\Gamma}{\Gamma_1}&\ldots&\yield{a_n,\Gamma_{n-1}}{\Gamma_n}}
    {\yield{\textsc{state}(q,\tuple{a_1,\ldots,a_n}),\Gamma}{\Gamma_n}}
\]

\[
    \inference[EventDef]
    {\yield{x_a,\Gamma}{\Gamma'}&\yield{x_{\delta_a},\Gamma'}{\Gamma''}\\
     \yield{x_{\check{\delta}_1},\Gamma''}{\Gamma_1}&\ldots&\yield{x_{\check{\delta}_n},\Gamma_{n-1}}{\Gamma_n}}
    {\yield{\textsc{event}(x_a,\tuple{\check{\delta}_1,\ldots,\check{\delta}_n}),\Gamma}{\Gamma_n}}
\]

\[
    \inference[NameDef]
    {x\not\in\dom\Gamma&\alpha\isfresh}
    {\yield{\textsc{name}(x),\Gamma}{\Gamma\left\{x\mapsto\alpha\right\}}}
\]

\[
    \inference[NameDefAlready]
    {x\in\dom\Gamma}
    {\yield{\textsc{name}(x),\Gamma}{\Gamma}}
\]

\subsection*{Constraint rules}
Constraints are accumulated over the elaboration of a module, and then
satisfied during unification.  The function \texttt{typefor} is not specified,
but must be a deterministic, bijective mapping of names to types.
\[
    \inference[StateMachine]
    {\proves{C,\Gamma}{q_1,\ldots,q_n}}
    {\proves{C,\Gamma}{\textsc{statemachine}(m,\tuple{q_1,\ldots,q_n})}}
\]

\[
    \inference[State]
    {\proves{C,\Gamma}{a_1,\ldots,a_n}}
    {\proves{C,\Gamma}{\textsc{state}(q,\tuple{a_1,\ldots,a_n})}}
\]

\[
    \inference[Event]
    {\proves{C,\Gamma,x_a}{\delta_a,\check{\delta}_1,\ldots,\check{\delta}_n}&\tau=\texttt{typefor}(x_a)}
    {\proves{\tau\instantiates\Gamma(x_a)\land C,\Gamma}
             {\textsc{event}(x_a,\tuple{\check{\delta}_1,\ldots,\check{\delta}_n})}}
\]

\[
    \inference[SideEffectFunction]
    {\Gamma(x_a)=\tau_{a}}
    {\proves{\tau_{a}\rightarrow\void\instantiates\Gamma(x_\delta),\Gamma,x_a}{\tuple{x_\delta,\textsc{function}}}}
\]

\[
    \inference[SideEffectTyped]
    {\Gamma(x_a)=\tau_{a}\\
     x_{a'}\in\dom\Gamma&\Gamma(x_{a'})=\tau_{a'}}
    {\proves{\tau_{a}\rightarrow\tau_{a'}\instantiates\Gamma(x_\delta),\Gamma,x_a}{\tuple{x_\delta,\textsc{typed}(x_{a'})}}}
\]

\[
    \inference[SideEffectEvent]
    {x_{a'}\in\dom\Gamma&\Gamma(x_{a'})=\tau_{a'}}
    {\proves{\tau_{a'}\rightarrow\void\instantiates\Gamma(x_\delta),\Gamma,x_a}{\tuple{x_\delta,\textsc{eventfunction}(x_{a'})}}}
\]

\subsection*{Monomorphic unification rules}
These rules dictate type resolution in the case where the types must match.
This behavior can be selected by supplying a flag at invocation.  It resolves
conflicting constraints by rejecting the module as ill-formed.

\[
    \inference[SubtypeEqual]
    {\tau_1=\tau_2}{\tau_1\instantiates\tau_2}
\]

\[
    \inference[Conjoin]
    {C_1\issatisfied&C_2\issatisfied}
    {C_1\land C_2\issatisfied}
\]

\subsection*{Subtype polymorphic unification rules}
The default unification method is to simplify the types using polymorphism.  It
is instructive to first consider a non-deterministic rule for simplification.
According to this rule, a simplified type is a type that is strictly more
general than either of two other types, such that these two types are subtypes
of it.
\[
    \inference[SimplifyNonDeterministic]
    {\hastype{\Gamma}{\check{\delta}_1}{\tau_1\times\ldots\times\tau_n\rightarrow\tau}\\
     \hastype{\Gamma}{\check{\delta}_2}{\tau_1'\times\ldots\times\tau_m'\rightarrow\tau'}\\
     \tau_1\times\ldots\times\tau_n\rightarrow\tau\instantiates\tau_1''\times\ldots\times\tau_k''\rightarrow\tau''\\
     \tau_1'\times\ldots\times\tau_m'\rightarrow\tau'\instantiates\tau_1''\times\ldots\times\tau_k''\rightarrow\tau''}
    {\hastype{\Gamma}{\textsc{simplify}(\check{\delta}_1, \check{\delta}_2)}{\tau_1''\times\ldots\times\tau_k''\rightarrow\tau''}}
\]

However, this definition is insufficient to specify the actual result of type
unification.  For this, the accumulated constraints must be resolved into a
supertype through additional rules that build on top of the monomorphic ones.

These include the basic subtyping rules that dictate structural relationships
directly between types.  For clarity the n-ary rule is included, although it is
implicit in the arrow rule.

A key detail worth drawing attention to in these rules is that function return
and parameter types are generalized in the opposite direction --- return types
covariantly, and parameter types contravariantly.  This is because for a
function, a concrete return type is actually a more general type.

\[
    \inference[SubtypeVoid]
    {}{\void\instantiates\tau}
\]

\[
    \inference[SubtypeReflexive]
    {}{\tau\instantiates\tau}
\]

\[
    \inference[SubtypeArrow]
    {\tau''\instantiates\tau&\tau'\instantiates\tau'''}
    {\tau\rightarrow\tau'\instantiates\tau''\rightarrow\tau'''}
\]

\[
    \inference[SubtypeN-ary]
    {\tau_1'\instantiates\tau_1&\tau_2\times\ldots\times\tau_n\rightarrow\tau\instantiates\tau_2'\times\ldots\times\tau_n'\rightarrow\tau'}
    {\tau_1\times\tau_2\times\ldots\times\tau_n\rightarrow\tau\instantiates\tau_1'\times\tau_2'\times\ldots\times\tau_n'\rightarrow\tau'}
\]

In addition, meet and join rules dictate relationships that are use-dependent.
Although Smudge is only capable of directly inferring joins, meet rules are
required to resolve parameter contravariance.

\[
    \inference[SubtypeMeetLeft]
    {}{\tau_1\land\tau_2\instantiates\tau_1}
\]

\[
    \inference[SubtypeMeetRight]
    {}{\tau_1\land\tau_2\instantiates\tau_2}
\]

\[
    \inference[SubtypeMeet]
    {\tau\instantiates\tau_1&\tau\instantiates\tau_2}
    {\tau\instantiates\tau_1\land\tau_2}
\]

\[
    \inference[SubtypeJoinLeft]
    {}{\tau_1\instantiates\tau_1\lor\tau_2}
\]

\[
    \inference[SubtypeJoinRight]
    {}{\tau_2\instantiates\tau_1\lor\tau_2}
\]

\[
    \inference[SubtypeJoin]
    {\tau_1\instantiates\tau&\tau_2\instantiates\tau}
    {\tau_1\lor\tau_2\instantiates\tau}
\]

\[
    \inference[SubtypeJoinArrow]
    {}
    {\tau\rightarrow\tau'\lor\tau''\rightarrow\tau'''\instantiates
     (\tau''\land\tau)\rightarrow(\tau'\lor\tau''')}
\]

\section*{Name mangling in Smudge}

For most backends, the input alphabet of Smudge identifiers is larger than the
output alphabet because Smudge identifiers can include, e.g., non-alphanumeric
symbols and whitespace.

As a consequence, those backends are required to somehow translate identifiers
into their output alphabet.  This process is known as name mangling.

Because of the nature of identifiers, an important goal for any name mangling
translation is to maintain their uniqueness: it should be injective, i.e., no
two qualified input identifiers should yield the same output identifier.  The
basis for this is intuitive: static checks are run on unmangled identifiers,
not mangled identifiers.  If two Smudge identifiers mangle to the same output,
the correctness of those checks is not preserved; this will lead to errors in
the output.  While some of them will be caught by static checks in the target
compiler, others could result in runtime errors.

Because the mangled names generated by Smudge have to be used externally, it
also makes sense to try to mangle the minimum possible while maintaining
injectivity.

\subsection*{Name mangling in the C backend}

Identifiers in C are the language \verb|[_a-zA-Z][_a-zA-Z0-9]*|.

To map into this space as densely as possible, unqualified Smudge identifiers
are handled as three different cases:

\begin{enumerate}
    \item \verb|[a-zA-Z][a-zA-Z0-9]*| \\
        The mapping is identity.
    \item \verb|[a-zA-Z0-9]+(_[a-zA-Z0-9]+)*| \\
        The mapping is identity wrapped in leading and trailing underscores.
    \item \verb|.*| \\
        The mapping is to prepend two underscores, the decimal length, and an
        underscore, i.e., \verb|__len_|, and mangle each character as follows:
        \begin{enumerate}
            \item \verb|[a-zA-Z0-9]| \\
                The mapping is identity.
            \item \verb|_| \\
                The mapping is double underscore.
            \item \verb|.| \\
                The mapping is the UTF-8 hexadecimal encoding of the character
                wrapped in leading and trailing underscores.
        \end{enumerate}
\end{enumerate}

Qualified identifiers are mangled by mangling unqualified identifiers, and then
joining them by concatenation with an underscore.

In order to prove the injectivity of the overall translation, the unqualified,
qualified, and single character translations can be separately proven
injective.  Because the overall translation is a composition of these, if they
are individually injective, then the composition is injective.  An informal
proof follows.

The single character translation uses identity on alphanumeric characters,
which is injective with respect to itself.  Underscores are doubled, which is
trivially injective with respect to itself, and which cannot produce an
alphanumeric character, and alphanumeric character identity cannot produce two
underscores, so these are injective with respect to each other.  Otherwise, the
character is translated to a hexadecimal number wrapped by underscores; this
number is assumed to be an injective mapping defined by UTF-8, and because it
is wrapped by underscores, it cannot produce a lone alphanumeric character, and
since all numbers are at least one digit long and contain no underscores, it
cannot produce an output consisting solely of underscores, and thus it is
injective with respect to itself as well as the other two cases; finally,
alphanumeric character identity cannot produce underscores, and doubling
underscores cannot produce hexadecimal numbers.  All cases are injective with
respect to themselves and each other, and so single character translation is
injective.

The concatenation of the output of the single character translation can be
proven injective by induction on the length of the input.  The single character
base case is presented previously.  A total function with only positive-length
outputs, the empty string is thus also injective.  The inductive hypothesis is
that all inputs $b_1\ldots b_k$ of length $k$ are injective with respect to all
inputs $a_1\ldots a_j$ of length $j\leq k$ .  The proof of the induction is by
contradiction: assume there are two such inputs $a\neq b$ of length $j+1$ and
$k+1$ respectively s.t.
\begin{align*}
    t(a_1)+\ldots+t(a_j)+t(a_{j+1})&=    t(b_1)+\ldots+t(b_k)+t(b_{k+1})\\
    t(a_1)+\ldots+t(a_j)           &\neq t(b_1)+\ldots+t(b_k)
\end{align*}
where $t()$ denotes single character translation and plus denotes
concatenation.  In order for this to be the case, either $t(a_1)+\ldots+t(a_j)$
or $t(b_1)+\ldots+t(b_k)$ must be a proper prefix of the other\footnote{It
doesn't matter which, because the same arguments would apply.}; say it is
$t(a_1)+\ldots+t(a_j)$.  As such, $t(a_{j+1})$ is a proper suffix of
$t(b_1)+\ldots+t(b_{k+1})$, which means more simply that either $t(a_{j+1})$ or
$t(b_{k+1})$ is a suffix of the other.  Consider the cases of the single
character translation: alphanumeric identity, underscore doubling, and UTF-8
underscore wrapping produce outputs of length 1, 2, and at least 3,
respectively, which means that the latter cannot suffix the former;
alphanumeric identity cannot produce underscores, and so cannot be a suffix of
the other cases; finally, UTF-8 underscore wrapping has a lone underscore
suffix, no more, while underscore doubling cannot produce a lone underscore,
only more.  Thus neither $t(a_{j+1})$ nor $t(b_{k+1})$ can be a proper suffix
of the other, so they must be equal.  As as $t(a_{j+1})=t(b_{k+1})$, trimming
them off of their respective outputs gives
\[t(a_1)+\ldots+t(a_j)=t(b_1)+\ldots+t(b_k)\]
which contradicts the premise that they differ.  Thus, $a=b$ and the
concatenation for lengths $j+1, k+1$ is injective for all $k,j\leq k$.
Concatenation is associative, so this is true for prepending as well.

The unqualified identifier translation uses identity on strings with an initial
upper- or lower-case letter followed by any number of alphanumeric characters
(the ``alphanumeric'' case), which is injective with respect to itself.
Strings composed of alphanumeric characters separated by lone underscores (the
``single underscore'' case) are translated using identity wrapped by a leading
and trailing underscore, which is injective with respect to itself because
identity and concatenation with a fixed pattern are both injective, and since
it cannot produce purely alphanumeric output and the alphanumeric case cannot
produce leading and trailing underscores, these cases are injective with
respect to each other.  Otherwise (the ``general'' case), the translation is
two underscores followed by the input length encoded in decimal followed by an
underscore followed by the concatenation of the single character translation
applied to the input, presented previously; decimal natural number encoding is
injective, as is concatenation with the stated fixed underscore pattern, and
because concatenation of the single character translation is injective there
are no two inputs of the same lengths that produce the same output, and as it
produces output with two leading underscores, it cannot produce output with a
leading alphanumeric character or solitary underscore, so overall this
translation is injective with respect to itself as well as the other two cases;
finally, neither the alphanumeric nor single underscore case can produce two
leading underscores.  All cases are injective with respect to themselves and
each other, and so unqualified identifier translation is injective.

The qualified identifier translation, a concatenation of the output of the
unqualified identifier translation intercalated with underscores, can be proven
injective by induction on the length of the input.  The single identifier base
case is presented previously.  A total function with only non-negative-length
outputs, the empty qualified identifier is thus also injective.  The inductive
hypothesis is that all inputs $y_k\ldots y_1$ of length $k$ are injective with
respect to all inputs $x_j\ldots x_1$ of length $j\leq k$.  The proof of the
induction is by contradiction: assume there are two such inputs $x\neq y$ of
length $j+1$ and $k+1$ respectively s.t.
\begin{myverbbox}{\vunder}_\end{myverbbox}
\begin{align*}
    u(x_{j+1})+\vunder+u(x_j)+\vunder+\ldots+u(x_1)&=    u(y_{k+1})+\vunder+u(y_k)+\vunder+\ldots+u(y_1)\\
                       u(x_j)+\vunder+\ldots+u(x_1)&\neq                    u(y_k)+\vunder+\ldots+u(y_1)
\end{align*}
where $u()$ denotes unqualified identifier translation, all underscores are
literals, and plus denotes concatenation.  In order for this to be the case,
either \mbox{$u(x_j)+\vunder+\ldots+u(x_1)$} or $u(y_k)+\vunder+\ldots+u(y_1)$
must be a proper suffix of the other\footnote{Again, it doesn't matter which};
say it is $u(x_j)+\vunder+\ldots+u(x_1)$.  As such, $u(x_{j+1})+\vunder$ is a
proper prefix of $u(y_{k+1})+\vunder+\ldots+u(y_1)$, which means more simply
that either $u(x_{j+1})+\vunder$ or $u(y_{k+1})+\vunder$ is a prefix of the
other\footnote{Without the intercalated underscore, trivial examples of output
prefixing can easily be produced; as such, the rest of the proof requires the
intercalated underscore.}.  Consider the cases of the unqualified identifier
translation: the alphanumeric case, the single underscore case, and the general
case, each with an underscore appended.  The alphanumeric case output cannot
have a leading underscore so it cannot be a prefix of the other two cases.  The
appended underscore prevents its output from being a proper prefix of other
alphanumeric case outputs, as underscore is not in the output alphabet.  The
single underscore case starts with exactly one leading underscore so it cannot
be a prefix of the other two cases.  The appended underscore prevents its
output from being a proper prefix of other single underscore case outputs,
which cannot contain a sequence of two underscores.  The general case starts
with two underscores so it cannot be a prefix of the other two cases.  With
respect to itself, the appended underscore does not help the general case;
instead, the length code is used.  The length prefix is injective with respect
to the length of the input identifier, thus if $u(x_{j+1})+\vunder$ or
$u(y_{k+1})+\vunder$ prefixes the other, $x_{j+1}$ and $y_{k+1}$ must have the
same length.  If the translation of a prefix of either input could equal the
translation of the entirety of the other, this would be a violation of the
injectivity already proven in the unqualified case.  Thus neither
$u(x_{j+1})+\vunder$ nor $u(y_{k+1})+\vunder$ can be a proper prefix of the
other, so they must be equal.  As as $u(x_{j+1})+\vunder=u(y_{k+1})+\vunder$,
trimming them off of their respective outputs gives
\[u(x_j)+\vunder+\ldots+u(x_1)=u(y_k)+\vunder+\ldots+u(y_1)\]
which contradicts the premise that they differ.  Thus, $x=y$ and the
concatenation for lengths $j+1, k+1$ is injective for all $k,j\leq k$.
Concatenation is associative, so this is true for appending as
well\footnote{Although the proof in that direction is more convoluted, because
all cases can output proper suffixes of some general case output.}.

With the unqualified, qualified, and single character translations separately
proven injective, and as the overall translation is a composition of these, the
overall translation is thus proven injective.\qed

\end{document}
